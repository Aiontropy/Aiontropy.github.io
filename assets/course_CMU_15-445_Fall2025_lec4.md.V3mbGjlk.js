import{_ as e,c as l,o as s,ae as n}from"./chunks/framework.BD_Yrv4e.js";const u=JSON.parse('{"title":"Memory Management & Buffer Pools","description":"","frontmatter":{},"headers":[],"relativePath":"course/CMU_15-445_Fall2025/lec4.md","filePath":"course/CMU_15-445_Fall2025/lec4.md"}'),o={name:"course/CMU_15-445_Fall2025/lec4.md"};function t(r,a,p,c,i,d){return s(),l("div",null,[...a[0]||(a[0]=[n(`<h1 id="memory-management-buffer-pools" tabindex="-1">Memory Management &amp; Buffer Pools <a class="header-anchor" href="#memory-management-buffer-pools" aria-label="Permalink to &quot;Memory Management &amp; Buffer Pools&quot;">​</a></h1><h2 id="database-storage" tabindex="-1">Database Storage <a class="header-anchor" href="#database-storage" aria-label="Permalink to &quot;Database Storage&quot;">​</a></h2><h3 id="spatial-control" tabindex="-1">Spatial Control <a class="header-anchor" href="#spatial-control" aria-label="Permalink to &quot;Spatial Control&quot;">​</a></h3><p>跟踪被写入磁盘的数据的位置，尽量让他们存放在连续的位置，以方便读取的时候可以读取连续的数据，尤其是机械硬盘，提升十分显著。</p><h3 id="temporal-control" tabindex="-1">Temporal Control <a class="header-anchor" href="#temporal-control" aria-label="Permalink to &quot;Temporal Control&quot;">​</a></h3><p>考虑什么时候将数据页读入内存，什么时候将脏页写回磁盘，尽可能预测需要被读取的页读入内存中，延迟脏页写回磁盘的时间，以减少 I/O 的次数。</p><h2 id="buffer-pool-meta-data" tabindex="-1">Buffer Pool Meta-Data <a class="header-anchor" href="#buffer-pool-meta-data" aria-label="Permalink to &quot;Buffer Pool Meta-Data&quot;">​</a></h2><p>实际上 Buffer Pool 也是有一个 Page table 在 Buffer Pool 的内存的前面，它用于查找内存中或不存在内存中的页面，以及检查它们是否在内存中。<br> 类似于哈希表， Page Table 存储 Page ID ，当需要使用某个 Page 时，通过 Page ID 判断 Page 是否存在 Buffer Pool 中，如果存在，在哪个位置。</p><p>Page Table 中还会存储一些 meta-data ，例如 Dirty Flag, Pin/Reference Counter, Access Tracking Information</p><h2 id="locks-vs-latches" tabindex="-1">Locks vs. Latches <a class="header-anchor" href="#locks-vs-latches" aria-label="Permalink to &quot;Locks vs. Latches&quot;">​</a></h2><p>Locks 保护逻辑数据，服务于事务；Latches 保护物理数据结构，服务于线程。</p><p>Locks 由 Lock Manager 提供， Latches 由数据库开发者提供。</p><p>Locks 持续时间长，有回滚，Latches 持续时间短，没有回滚。</p><h2 id="page-table-vs-page-directory" tabindex="-1">Page Table vs. Page Directory <a class="header-anchor" href="#page-table-vs-page-directory" aria-label="Permalink to &quot;Page Table vs. Page Directory&quot;">​</a></h2><p>Page table 是 Buffer Pool 在内存中用于寻找 Page 的，它不需要被存储在磁盘中。<br> Page Directory 是 DBMS 在磁盘中用于寻找 Page 的，它需要被存储在磁盘中。</p><h2 id="memory-mapped-i-o-problems" tabindex="-1">Memory Mapped I/O Problems <a class="header-anchor" href="#memory-mapped-i-o-problems" aria-label="Permalink to &quot;Memory Mapped I/O Problems&quot;">​</a></h2><p>使用 <code>mmap</code> 会导致的问题：</p><ol><li>Transaction Safety <ul><li>OS 有可能在任何时候将脏页写回磁盘中</li></ul></li><li>I/O Stalls <ul><li>DBMS 不知道 Pages 是否在内存中，如果不在内存中，会出现 Page Fault Stalls</li></ul></li><li>Error Handing <ul><li>OS 不能校验 Page 是否正确，而当出现读取文件出错时，OS 会无法处理错误，默认情况下， OS 会直接 kill 数据库服务</li></ul></li><li>Performance Issues <ul><li>OS 数据结构竞争，多核 CPU 频繁的争抢内核锁，会导致性能下降，频繁的页面换入换出会导致 TLB Shootdown</li></ul></li></ol><h2 id="buffer-replacement-policies" tabindex="-1">Buffer Replacement Policies <a class="header-anchor" href="#buffer-replacement-policies" aria-label="Permalink to &quot;Buffer Replacement Policies&quot;">​</a></h2><p>当 DBMS 需要释放一些 Buffer Pool 中的 Page 时，会使用缓存替换策略。</p><p>缓存替换策略至少需要满足：正确性、准确性、速度、内存开销</p><h3 id="lru-least-recently-used-1965" tabindex="-1">LRU: Least-Recently Used (1965) <a class="header-anchor" href="#lru-least-recently-used-1965" aria-label="Permalink to &quot;LRU: Least-Recently Used (1965)&quot;">​</a></h3><p>LRU 算法的基本思想：只需要根据上次访问的时间来跟踪内存中所有 Page 的 Timestamp ，在需要释放 Page 时，直接释放上次访问时间是最早的 Page ，而每次访问 Page 时，只需要更新 timestamp 。</p><p>LRU 存在一个严重的问题 Sequential Flooding ，当使用一次全表扫描，它会顺序读取大量页面。这些页面都只被访问一次，但它们会把 LRU 缓存中那些真正“热门”的、被频繁访问的 Page 全部冲刷出去。</p><h3 id="clock-second-chance-1969" tabindex="-1">Clock (Second-Chance) (1969) <a class="header-anchor" href="#clock-second-chance-1969" aria-label="Permalink to &quot;Clock (Second-Chance) (1969)&quot;">​</a></h3><p>Clock 让每个 Page 都有一个简单的 reference bit ，通常只有一个 bit ，然后维护一个环形数组，有一个“时钟指针”指向它，当需要释放页面的时候，查看指针指向的 Frame ，当 Frame 里面的 bit 为 1 时，将它设置为 0 ，当 Frame 里面的 bit 为 0 时，将它释放。每次使用 Page 时，将 bit 设置为 1 。</p><p>通俗易懂的说，就是在我上次检查之后，找到一个没有被访问过的 Page 。<br> 在 Linux 的内部，页表也是使用的这个算法。</p><p>Clock 算法是一个近似 LRU 的算法，它避免了为每次访问都更新时间戳和维护复杂数据结构的开销。</p><p>但是 Clock 也没有解决 LRU 的 Sequential Flooding 问题，也就是当全表扫描时，不管是“热门” Page 还是“冷门” Page 都会变得相同。</p><h3 id="lfu-least-frequently-used-1971" tabindex="-1">LFU: Least Frequently Used (1971) <a class="header-anchor" href="#lfu-least-frequently-used-1971" aria-label="Permalink to &quot;LFU: Least Frequently Used (1971)&quot;">​</a></h3><p>LFU 的基本思想是为每个 Page 维护一个 Counter ，每次访问 Counter + 1 ，当需要释放 Page 时找到 Counter 最小的 Page 释放掉。</p><p>LFU 解决了 Sequential Flooding 的问题，但是同时也诞生了更多的问题：</p><ol><li>是需要维护一个更复杂的数据结构</li><li>The &quot;New Page&quot; Problem <blockquote><p>当 Buffer Pool 中满了，需要读取新的 Page 时，当读取了一个“热点” Page 时，旧的 Page 由于长时间呆在 Buffer Pool 中，即使不再需要它，它的 Counter 还是很高，而新的 Page 即使很“热门” ，也还是会被清除。</p></blockquote></li></ol><h3 id="lru-k-1993" tabindex="-1">LRU-K (1993) <a class="header-anchor" href="#lru-k-1993" aria-label="Permalink to &quot;LRU-K (1993)&quot;">​</a></h3><p>LRU-K 的基本思想是维护多个 LRU 列表，当需要释放某些 Page 时，替换掉倒数第 K 次访问最古老的 Page 。</p><h4 id="ghost-cache" tabindex="-1">Ghost Cache <a class="header-anchor" href="#ghost-cache" aria-label="Permalink to &quot;Ghost Cache&quot;">​</a></h4><p>LRU-K 有一个缺陷，它会清除被释放的 Page 的历史。<br> 当有一个有“热度”，但是“热度”不是最高的 Page 需要被清除，这时不希望它的访问记录被清空，就可以使用 Ghost Cache 。</p><p>Ghoth Cache 的基本思想就是在释放 Page 的时候，不清除访问记录。</p><h3 id="arc-adaptive-replacement-cache-2003" tabindex="-1">ARC Adaptive Replacement Cache (2003) <a class="header-anchor" href="#arc-adaptive-replacement-cache-2003" aria-label="Permalink to &quot;ARC Adaptive Replacement Cache (2003)&quot;">​</a></h3><p>ARC 是一个自适应的缓存算法，它动态地平衡 LRU (新近度) 和 LFU (频率) 两种策略，以自动适应当前的工作负载，无需手动调参。</p><p>ARC 需要维护两个 Real 列表和两个Ghost 列表，它们都是 LRU 列表。<br> Real 列表：</p><ol><li>T1(Top 1): 存放最近只被访问一次的 Page ，这个列表用于记录 Recency</li><li>T2(Top 2): 存放最近被访问至少两次的 Page ，这个列表用于记录 Frequecy<br><code>T1</code> 和 <code>T2</code> 的大小是动态变化的，它们的总和 <code>|T1| + |T2| = c</code> 。ARC 算法的核心就是调整 <code>T1</code> 和 <code>T2</code> 的相对大小。</li></ol><p>Ghost 列表:</p><ol><li>B1(Bottom 1): 存放从 T1 中释放的 Page 的 meta-data ，它代表了<strong>最近被访问过一次就被淘汰</strong>的历史。</li><li>存放从 T2 中淘汰出去的 Page 的 meta-data。它代表了<strong>曾经是热点但最近被释放</strong>的历史。<br><code>B1</code> 和 <code>B2</code> 的大小也是动态的，它们的总和 <code>|B1| + |B2| = c</code>。</li></ol><p>ARC 的 Adaptive 是通过一个目标参数 <code>p</code> 来控制 T1 的理想大小， T2 的理想大小就是 <code>c - p</code> 。</p><p>Gemini:</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>工作流程与决策：</span></span>
<span class="line"><span></span></span>
<span class="line"><span>情况一：一个新页面被访问 (Cache Miss)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    检查幽灵列表:</span></span>
<span class="line"><span>        如果在 B1 中找到了: 这意味着一个“只访问过一次”的页面被淘汰后，很快又被需要了。这说明偏重“新近度”的 LRU 策略可能很有用，T1 列表可能太小了。</span></span>
<span class="line"><span>            动作: 增大 T1 的目标大小 p。然后将页面加载到 T2（因为它现在被访问了第二次，晋升为“老兵”）。</span></span>
<span class="line"><span>        如果在 B2 中找到了: 这意味着一个“被多次访问”的页面被淘汰后，很快又被需要了。这说明偏重“频率”的 LFU 策略可能很有用，T2 列表可能太小了。</span></span>
<span class="line"><span>            动作: 减小 T1 的目标大小 p（从而增大 T2 的大小）。然后将页面加载到 T2。</span></span>
<span class="line"><span>        如果哪里都没找到: 这是个全新的页面。</span></span>
<span class="line"><span>            动作: 将页面加载到 T1 (作为“新来者”)。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    腾出空间: 加载新页面前，如果缓存已满 |T1| + |T2| == c，需要淘汰一个页面：</span></span>
<span class="line"><span>        如果 T1 的当前大小 |T1| 大于等于目标值 p，则从 T1 的尾部淘汰一个页面，并将其元数据移入 B1 的头部。</span></span>
<span class="line"><span>        否则，从 T2 的尾部淘汰一个页面，并将其元数据移入 B2 的头部。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>情况二：一个已在缓存中的页面被访问 (Cache Hit)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    如果在 T1 中命中: 说明这个“新来者”很有潜力，它被访问了第二次。</span></span>
<span class="line"><span>        动作: 将它从 T1 移动到 T2 的头部（晋升为“老兵”）。</span></span>
<span class="line"><span>    如果在 T2 中命中: 说明这个“老兵”持续热门。</span></span>
<span class="line"><span>        动作: 将它移动到 T2 的头部（刷新其新近度）。</span></span></code></pre></div><h2 id="dirty-page" tabindex="-1">Dirty Page <a class="header-anchor" href="#dirty-page" aria-label="Permalink to &quot;Dirty Page&quot;">​</a></h2><p>当需要释放 Page 时，碰到了 Dirty Page ，通常不会选择先将 Dirty Page 写入磁盘，这样做速度很慢。</p><p>最常用的做法是 Background Writer / Flusher ，系统会有一个或多个专门的后台线程，它们的任务就是定期、主动地将 Dirty Page 写回磁盘。<br> 第二种做法是单纯的优先选择普通 Page 。</p>`,50)])])}const P=e(o,[["render",t]]);export{u as __pageData,P as default};
